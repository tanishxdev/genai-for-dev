
# **Topic 3 — Multi-Turn Conversations (Chat API)**

---

## **1. Concept**

So far, you’ve been making **single-prompt requests**:

```js
ai.models.generateContent({ model, contents })
```

That’s called a **stateless interaction** — every request is independent.

In contrast, **multi-turn chat** allows you to keep a conversation history:

* You send a prompt
* Gemini replies
* Next message includes all previous turns (history)
* Model understands the context

This makes Gemini behave like a real conversational agent.

---

## **2. What Happens Internally**

Each chat session maintains:

* **history:** list of messages between `user` and `model`
* **context:** what’s been discussed so far
* **session object:** created once per chat, reused for every turn

---

## **3. Chat Object in Gemini SDK**

Gemini provides a helper interface:

```js
const chat = ai.chats.create({
  model: "gemini-2.5-flash",
  history: [
    { role: "user", parts: [{ text: "Hello" }] },
    { role: "model", parts: [{ text: "Hi there!" }] }
  ],
});
```

Then you can continue the conversation:

```js
const response = await chat.sendMessage({
  message: "Tell me a joke about AI",
});
console.log(response.text);
```

The `chat` object automatically keeps updating its `history`.

---

## **4. Code Example: Chat Session**

**File:** `src/05.chat-session.js`

```js
// -------------------------------------------------------------
// GOAL: Demonstrate multi-turn chat with Gemini SDK
// -------------------------------------------------------------
// Concepts:
// - Create a chat session with history
// - Send multiple messages
// - Maintain context between turns
// -------------------------------------------------------------

import ai from "../utils/geminiClient.js";

async function main() {
  console.log("Starting multi-turn chat...\n");

  // 1️⃣ Create a new chat session
  const chat = ai.chats.create({
    model: "gemini-2.5-flash",
    history: [
      {
        role: "user",
        parts: [{ text: "Hello" }],
      },
      {
        role: "model",
        parts: [{ text: "Hi! I'm Gemini, your AI assistant. How can I help you today?" }],
      },
    ],
  });

  // 2️⃣ First message
  const response1 = await chat.sendMessage({
    message: "I have 2 dogs at home.",
  });
  console.log("User: I have 2 dogs at home.");
  console.log("Gemini:", response1.text, "\n");

  // 3️⃣ Second message – model should remember previous info
  const response2 = await chat.sendMessage({
    message: "How many paws are there in my house?",
  });
  console.log("User: How many paws are there in my house?");
  console.log("Gemini:", response2.text, "\n");

  // 4️⃣ Third message – continues with context
  const response3 = await chat.sendMessage({
    message: "What are some fun activities for them?",
  });
  console.log("User: What are some fun activities for them?");
  console.log("Gemini:", response3.text, "\n");
}

await main();
```

---

### **Expected Output**

```
Starting multi-turn chat...

User: I have 2 dogs at home.
Gemini: That sounds lovely! Dogs bring great joy to a home.

User: How many paws are there in my house?
Gemini: Since each dog has 4 paws, you have 8 paws in your house.

User: What are some fun activities for them?
Gemini: You can try fetch, tug-of-war, or short agility exercises in the backyard.
```

---

## **5. Streaming Version (Optional)**

To make responses appear progressively, use `sendMessageStream()`:

```js
const stream = await chat.sendMessageStream({
  message: "Tell me about AI trends in 2025.",
});

for await (const chunk of stream) {
  const text = chunk.text;
  if (text) process.stdout.write(text);
}
```

---

## **6. Concept: Chat vs Stateless Calls**

| Feature             | `generateContent()` | `chats.create()`         |
| ------------------- | ------------------- | ------------------------ |
| Context memory      | No                  | Yes                      |
| History tracking    | Manual              | Automatic                |
| Real conversation   | Harder              | Simple                   |
| Streaming supported | Yes                 | Yes                      |
| Ideal for           | One-off queries     | Agents, Assistants, Apps |

---

## **7. Notes for `/Topics OR Concepts/topic3/`**

**File:** `01.chat-sessions.md`

```
# Topic 3: Multi-Turn Chat Sessions

- Chats maintain history and context automatically.
- Use ai.chats.create() to initialize session.
- sendMessage() for normal message.
- sendMessageStream() for streaming chat.
- History persists within the chat object.
- Great for conversational agents and contextual assistants.

Example use cases:
- Customer support bots
- Interactive tutors
- Personal assistants
```

---

## **8. Practice Tasks**

1. Add one more user message like:
   `"What food should I give them?"`
   → Notice how Gemini remembers you’re talking about dogs.
2. Print `chat.history` at the end of the script to see full stored conversation.
3. Try switching the model to `"gemini-2.5-pro"` for deeper reasoning.

---

## **9. Summary**

You’ve now learned:

* How to create and manage chat sessions
* How to maintain context automatically
* How to stream chat responses in real time
* The difference between stateless and stateful interaction

---
