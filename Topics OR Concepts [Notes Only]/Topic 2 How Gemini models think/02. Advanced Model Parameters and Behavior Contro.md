# **Advanced Model Parameters & Behavior Control**

---

# **0. Purpose of This File**

This chapter goes beyond basic parameters like temperature or max tokens.

You will learn **how to fully control Gemini’s behavior**, including:

1. How prompts are structured inside the model
2. How Gemini decides which instruction to follow
3. How to prevent hallucination using deterministic pipelines
4. How to shape output using schema, MIME, templates
5. How to architect multi-model flows (Flash + Pro + Thinking)
6. How agents enforce rules through context engineering
7. How to partition context for reliability
8. How to design system, developer, user instructions with precedence rules

This is the foundation for reliable **agents**, **tools**, **reasoning systems**, and **production AI components**.

---

# **1. Prompt Scaffolding (Internal Prompt Construction)**

Gemini does NOT simply read your prompt as-is.

Internally, it constructs a **prompt scaffold** with layers:

```
[System Instruction]
[Developer Instruction]  (optional)
[User Input]
[Context Memory]         (chat history)
[Tool Results]           (if any)
[Schema/Formatting rules]
```

Each layer is fed into the model **in a specific order** which determines behavior.

---

## **1.1 The Prompt Stack (Precedence Order)**

From highest priority to lowest:

1. **System Instruction** (hard rules)
2. **Schema / MIME type rules** (hard constraints)
3. **Developer Instruction** (medium-hard)
4. **Tool Responses** (trusted data)
5. **User Message** (main target)
6. **Context History** (memory)
7. **Sampling Config** (affects randomness)

### **Precedence Summary:**

**System Instruction > Schema > Developer > Tools > User > History > Sampling**

This is extremely important.

Example:

If the system instruction says:

```
Always respond in JSON only.
```

And user says:

```
Write a poem.
```

Result is still JSON.

---

# **2. Context Partitioning (Production Technique)**

Context is not one block; it must be **segmented** to avoid interference.

### You must divide context into these zones:

1. **Hard rules**
2. **Formatting constraints**
3. **Examples / in-context demos**
4. **Live data / tool results**
5. **User input**
6. **Chat history** (only essential pieces)

---

## **2.1 Why Partition Context?**

Because mixing:

```
rules + examples + user text + history
```

in one block causes:

* loss of determinism
* rule overriding
* hallucinated formats
* incorrect schema outputs
* lower tool-selection accuracy

---

## **2.2 Techniques for Partitioning**

### Technique 1: Tag-based Partitioning

```
<RULES>
...</RULES>

<FORMAT>
...</FORMAT>

<EXAMPLES>
...</EXAMPLES>

<USER_MESSAGE>
...</USER_MESSAGE>
```

### Technique 2: Boundary instructions

```
Ignore everything outside <PAYLOAD>...</PAYLOAD>.
```

### Technique 3: Role separation (system vs user)

System = instructions
User = payload only

### Technique 4: Inject tool outputs separately

Never mix tool output with rules.

---

# **3. Instruction Precedence Rules (Critical)**

Gemini follows strict precedence.

| Layer | Type                  | Priority        | Description           |
| ----- | --------------------- | --------------- | --------------------- |
| 1     | System Instruction    | Highest         | Unbreakable rules     |
| 2     | responseSchema / MIME | Hard constraint | Forces valid format   |
| 3     | Developer Instruction | Medium          | Helps structure tasks |
| 4     | Tool Output           | Trusted         | Used for answering    |
| 5     | User Input            | Medium          | Task description      |
| 6     | History               | Lowest          | Memory only           |

---

## **3.1 When rules conflict**

Example:

System:

```
Respond in JSON only.
```

User:

```
Explain HTML with an example.
```

Output is still JSON.
User never overrides system.

---

## **3.2 How to Force Schema Over Everything**

```
responseMimeType: "application/json",
responseSchema: { ... }
```

Once schema is attached:

Model **MUST** produce valid JSON.
Even with high temperature.

---

# **4. Output-Shaping Patterns (Industrial)**

This is one of the most important parts.

## **Pattern A: JSON Output (Gemini's strongest)**

```
responseMimeType: "application/json"
responseSchema: { type: "object", ... }
temperature: 0.0–0.3
```

This yields deterministic, production-safe output.

---

## **Pattern B: Fixed Template Output**

Example:

```
<result>
{{text}}
</result>
```

Gemini follows templates very reliably.

---

## **Pattern C: Enum Responses**

Use:

```
responseMimeType: "application/x.enum",
```

With:

```
["yes", "no", "maybe"]
```

Gemini picks exactly one.

Used heavily in agents.

---

## **Pattern D: Multi-part Structured Output**

Example:

```
<analysis>...</analysis>
<answer>...</answer>
```

This lets you separate:

* hidden reasoning
* final answer

---

# **5. Deterministic vs Non-Deterministic Pipelines**

You must choose a pipeline type depending on use-case.

---

## **5.1 Deterministic Pipeline (Production Agents)**

Rules:

1. `temperature = 0.0–0.2`
2. `topK = 1`
3. `topP = 0.8`
4. `responseMimeType = "application/json"`
5. `responseSchema` enforced
6. `thinkingBudget = 0–20`
7. Define system rules explicitly

**Behavior:**
Stable, repeatable, safe.

**Used for:**

* agents
* structured extraction
* tool calling
* workflows

---

## **5.2 Non-Deterministic Pipeline (Creativity)**

Rules:

1. `temperature = 0.7–1.2`
2. `topP = 0.9–1.0`
3. `topK = 40–200`
4. No schema
5. No strict rules

**Used for:**

* writing
* brainstorming
* idea-generation

---

# **6. Agent-Specific Constraints (How Agents Stay Reliable)**

When building agents, you must enforce:

### **6.1 Allowed Tools List**

```
tools: [githubTool, weatherTool, ...]
```

Gemini will strictly choose among these.

---

### **6.2 Tool-Selection Biasing**

Add to system:

```
Call a tool only when necessary.
Do not fabricate data.
Prefer using tools for factual tasks.
```

---

### **6.3 Strict Schema for Final Output**

Example:

```
{
  "type": "object",
  "properties": {
     "action": {"type": "string"},
     "payload": {"type": "object"}
  },
  "required": ["action"]
}
```

Agent frameworks rely on such structures.

---

### **6.4 Reasoning Depth Control**

If agent is misbehaving:

Decrease thinkingBudget.
Agents should not over-think unless needed.

---

# **7. Multi-Model Orchestration (Flash + Pro + Thinking)**

Real systems do NOT use one model for everything.

**You orchestrate models like microservices.**

---

## **7.1 Common Pattern: Flash → Pro → Thinking**

### Step 1: Flash Model

Cheap, fast, used for:

* summarization
* data extraction
* boilerplate formatting

### Step 2: Pro Model

Used for:

* reasoning
* classification
* planning

### Step 3: Thinking Model

Used for:

* deep logic
* mathematical correctness
* high-risk reasoning

---

## **7.2 Example Use-Case: GitHub Agent**

1. Flash → fetch repo metadata
2. Pro → analyze issues, cluster tasks
3. Thinking → generate final action plan

---

# **8. Putting It All Together**

Below is the full template for **production requests**:

```js
const response = await ai.models.generateContent({
  model: "gemini-2.5-pro",
  systemInstruction: `
You are a strict JSON-only agent.
Follow the schema exactly.
Do not include explanations.
  `,

  responseMimeType: "application/json",
  responseSchema: {
    type: "object",
    properties: {
      summary: { type: "string" },
      score: { type: "number" }
    },
    required: ["summary"]
  },

  contents: userMessage,

  config: {
    temperature: 0.1,
    topK: 1,
    topP: 0.8,
    maxOutputTokens: 300,
    thinkingConfig: { thinkingBudget: 10 }
  }
});
```

This is how you build reliable pipelines.

---

# **9. Summary (Interview + Industry Ready)**

1. Prompts are layered; system instruction always wins.
2. Schema overrides all randomness and creativity.
3. Partitioning context improves reliability.
4. Deterministic pipelines are required for agents.
5. Sampling parameters shape token generation behavior.
6. Multi-model orchestration gives best performance + cost.
7. Output-shaping patterns prevent hallucination.
8. Instruction precedence is the core of model behavior control.

---
